\documentclass[11pt]{article}
\usepackage[top=0.5in, bottom=0.5in, left=0.5in, right=0.5in]{geometry}
\usepackage{helvet}
\usepackage{url} % hypderref?
\usepackage{graphicx}
\graphicspath{{figures/}} % The figures are in a figures/ subdirectory.
\renewcommand{\familydefault}{\sfdefault}
\pagestyle{empty}
%\pagestyle{plain}

\usepackage{setspace}
\usepackage{microtype}

\usepackage{amsfonts}
\usepackage{amsmath}

\usepackage{sidecap}
\usepackage[abs]{overpic}
\usepackage{wrapfig}

%\usepackage[round,authoryear]{natbib}
\usepackage{cite}
%\setlength{\bibsep}{0.00in}

\usepackage{hyperref}
\hypersetup{colorlinks=true, urlcolor=black, citecolor=black, linkcolor=black}

\newcommand{\doi}[1]{\href{http://dx.doi.org/#1}{doi:#1}}

\newcommand{\ac}[1]{{\sc \lowercase{#1}}}

\renewcommand{\baselinestretch}{.93}
%\renewcommand{\baselinestretch}{.90}
\usepackage{wrapfig} 

\usepackage{bibspacing}
\setlength{\bibspacing}{\baselineskip}


\graphicspath{{figs/}}

\makeatletter

\newcommand{\captionfonts}{\footnotesize}

\makeatletter  % Allow the use of @ in command names
\long\def\@makecaption#1#2{%
  \vskip\abovecaptionskip
  \sbox\@tempboxa{{\captionfonts #1: #2}}%
  \ifdim \wd\@tempboxa >\hsize
    {\captionfonts #1. #2\par}
  \else
    \hbox to\hsize{\hfil\box\@tempboxa\hfil}%
  \fi
  \vskip\belowcaptionskip}      
\makeatother

\renewcommand{\figurename}{Fig.}

% Page numbering.
%\pagestyle{plain}
%\pagenumbering{arabic}

\setlength{\abovecaptionskip}{-5pt}

\makeatother

\renewcommand{\refname}{Bibliography and References Cited}

\setlength{\parindent}{0pt} % Don't indent first line
\setlength{\parskip}{1ex plus 0.5ex minus 0.2ex} % Add some space between paragraphs

\begin{document}

%======================================

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% INTRODUCTION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%RESUBMISSION APPLICATIONS MUST INCLUDE AN INTRODUCTION
%You must include an introduction for all resubmission that:
% - summarizes substantial additions, deletions, and changes to the application
%    - individual changes do not need to be identified within other application attachments (e.g., do not need to bold or italicize changes in Research Strategy)
% - responds to the issues and criticism raised in the summary statement
% - is one page or less in length, unless specified otherwise in the FOA or is specified differently on our table of page limits.

\begin{centering}
{\bf INTRODUCTION}
\end{centering}

The reviewers of our original proposal raised a number of concerns we have addressed in the attached revised proposal and in this letter, as we detail below.

% Three biggest criticisms:
% - we're not innovating
Overall, reviewers had several main points of criticism, the most profound of which is that our proposal will not actually develop any new methods, but instead relies on others to do the methodological innovations, thus they concluded that ``as such, the overall impact... is expected to be limited and would rely largely on others to make progress.''
The reviewers are precisely right that (despite our groups' extensive work on method development) this proposal is focused on driving innovations across the field, but we (and the SAMPL community) believe the impact will be quite high. 
We now attach (and reference in the proposal) supporting documents from surveying the field about the impact of SAMPL, as well as testimonials from a number of past participants highlighting ways in which SAMPL has helped method development work in their groups which we believe will help address these concerns. 
Additionally, our model is very much aligned with the ``crowdsourcing for innovation'' model [ ref ] which has achieved widespread success at driving innovation in diverse fields, as we now discuss in the proposal. As argued elsewhere, this approach can actually foster much more innovation than having each group work independently on their own problems [ref]

% - it's not enough data for training on
Reviewers were also concerned that the data sets generated will not be large enough to provide a dramatic increase to the amount of data available for training. 
We fully agree -- SAMPL is about \emph{testing} not \emph{training} methods.
As with past crowdsourcing efforts, SAMPL focuses on providing a venue to find out what works and does not work in a blind predictive setting.
Existing datasets may be adequate for training, but it is also easy to overfit or unintentionally apply bias when studying existing data, so blind challenges like this (as Reviewer 2 noted) are particularly important by allowing all methods (both highly empirical methods relying extensively on training to existing data and physical methods like those we tend to prefer) to compete on equal footing.
We now make this more clear in the proposal in our section %section?
on crowdsourcing.
%Can we make a paralell to Netflix challenge here? 

% - it won't really advance the field
Reviewers also argued that, because of the size of data sets and the lack of methodological innovation, this work will not substantially advance the field. 
We now attach support letters from a variety of leaders in the field who are past SAMPL participants who highlight specific ways in which SAMPL has already served to advance the field, and we believe the roughly 100 (typically well-cited) publications about the SAMPL series of challenges also serve to make the point.

% Discuss surveys of community
To assist with this revision, we surveyed the SAMPL community regarding our plans for the challenge, and the community overwhelmingly supports our plans. 
Out of 45 respondents (each typically representing an individual group) 95.6\% saw SAMPL as a valuable resource to the community (with the remaining percentage seeing it as ``somewhat valuable'') and more than 90\% seeing it as important in driving progress in the field (with no respondents seeing it as unimportant). 91\% are happy with the proposed future directions, and the remaining 9\% had modest suggestions for refinements to our directions, such as increasing the size of the datasets modestly, doing additional experimental follow-up after SAMPL challenges, and increased use of 3rd party testing. 
We discuss some of these new innovations in our proposal; typically these will require expanding our planned work and make funding even more of an imperative.
% Discuss recommendations made which require funding

The reviewers also critiqued the perceived lack of participation in SAMPL, noting that only 20 groups participated this last cycle. 
We now address this in the proposal itself, but it is worth noting that this performance \emph{is increased} relative to previous SAMPL iterations since the protein-ligand binding component of prior SAMPL challenges has now been subsumed into D3R. 
Additionally, the 20 groups who participated include more than 100 co-authors all over the world, and this occurred even without any significant publicity effort for the SAMPL challenge and with continual uncertainty as to whether any future SAMPL challenge will ever occur. 
Without funding, it is always uncertain whether we can even have another iteration of the challenge, let alone when it will occur -- so it is difficult for us to advertise, and for researchers to plan on participating. 

Finally, the reviewers also objected that we have no apparent connection with the SAMPL challenge and that SAMPL's presence on the D3R website is not that extensive. 
We have updated the D3R website to clearly indicate the SAMPL organizers (including Mobley and Chodera), though having a substantial web presence for SAMPL is to some extent impaired by our lack of funding. 

Overall, we hope the overwhelming community support for our plans, the specific examples we now give of how SAMPL drives innovation in the field, and the ample precedent for ``crowdsourcing`` approaches to science innovation (as we now discuss in the proposal), coupled to our improvements to how we explain our ideas in the proposal itself, demonstrate that SAMPL will indeed drive progress in the field even more than it already has. 

% - Explain why appropriate for students (Reviewer 2 comment on budget)

%Changes (to have been) made to proposal to deal with these:
% - More detail on how experiments like those envisioned here have been more informative than existing datasets (Reviewer 2). Cite "lessons learned" from D3R challenges as an example versus lessons learned from SAMPL.
% - Updates to proposal to refer to supporting documents (SAMPL survey) on how SAMPL does and will have significant impact on the field; updates to make more clear that this is a crowdsourcing model of sorts like those which have proven track record (and history of NIH funding?)
% - Reviewer 3 - participants declining in SAMPL3. Analyze to show this is actually increase, even without advertising
% - Reviewer 3 - existing data is adequate; this new data is not cost effective to generate. Make more clear data is needed not because it is better/more than existing data (though to some extent that may be true!) but because it's blind and because of the challenge nature (see crowdsourcing). See also Reviewer 2 point 3 "strengths" which says these datasets do not exist; also point 4 strengths 1. 
% Reviewer 3 - better to have each lab work on their own targets separately? Reference bit from crowdsourcing review about how people are biased in evaluating own performance. (See also Reviewer 1)
% Appropriateness for students
% BASICALLY WE NEED A SPECIFIC BUT SHORT CROWDSOURCING SECTION IN PROPOSAL. Netflix prize, otehr examples... Llinas solubility challenge.

% The main weaknesses identified were as follows:
% Reviewer 1:
% - Simple systems may be too simple. Algorithms trained here may not extrapolate well to protein-drug interactions
% - Not listed as SAMPL committee on website
% - Not described how algorithms trained on simpler datasets can be used to predict more complex datasets
% - Not clear datasets are most relevant for drug design (mentions HSA, CB[n])
% - D3R website has scanty info on SAMPL; only 20 groups participated

% Reviewer 2: 
% - "I am missing key intellectual components in THIS proposal that would have a high likelihood to improve methods (this would have to come out of the community participating in the prediction challenges). As such, the overall impact of this work specifically is expected to be limited and would rely largely on others to make progress." 
% - "It is unclear what advances are likely as progress would come from others using the generated datasets to improve their methods."
% - "There are no new methods proposed"
% - "The main, but key, weakness is the lack of proposed methodological developments in this proposal."
% - Wants removal of repetitive points and more specifics on existing datasets, how they have not been informative and how new experiments such as the ones envisioned here have been

% Reviewer 3:
% - "The need for the research is made in vague terms and largely appeals to the broad need for improving computational predictions. The proposal does not identify what specific weakness in current methods is being targeted, nor what is inadequate in the existing experimental data for some of the SAMPL areas, nor how adding to the current experimental databases would actually impact predictive algorithms or methods. The community interest in SAMPL seems to be a relatively small group of researchers."
% - "needs a more specific explanation of why their efforts to add to existing data bases would have a significant impact on the field. It would require effort from other labs to actually realize a significant outcome." 
% - "There are a large number of challenges and data repositories for pKa's, affinities, physical properties, and it is difficult to see how this proposal for SAMPL is cost effective"
% - Questionable that community based engine will be effective at motivating innovative approaches.
% - It is not clear how this is better than having each group work on their own stuff in their own labs on actual targets. 
% - "Is there a real predictive algorithm where adding all of the host-guest affinities would make a difference?" 




%======================================

%\setlength{\bibsep}{0.000in}

%\bibliographystyle{gec_nih}
%\bibliographystyle{ieeetr}
%\bibliographystyle{myrefstyle}
%\bibliography{chodera-research}


\end{document}






